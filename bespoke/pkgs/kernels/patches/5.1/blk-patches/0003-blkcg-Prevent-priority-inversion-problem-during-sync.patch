From f1072cff7f9d27052e29824b6d562383f504b98e Mon Sep 17 00:00:00 2001
From: Andrea Righi <andrea.righi@canonical.com>
Date: Mon, 11 Mar 2019 11:40:07 +0200
Subject: [PATCH] blkcg: Prevent priority inversion problem during sync().
 Update [v4].

When sync(2) is executed from a high-priority cgroup, the process is
forced to wait the completion of the entire outstanding writeback I/O,
even the I/O that was originally generated by low-priority cgroups
potentially.

This may cause massive latencies to random processes (even
those running in the root cgroup) that shouldn't be I/O-throttled at
all, similarly to a classic priority inversion problem.

Prevent this problem by saving a list of blkcg's that are waiting for
writeback: every time a sync(2) is executed the current blkcg is added
to the list.

Then, when I/O is throttled, if there's a blkcg waiting for writeback
different than the current blkcg, no throttling is applied (we can
probably refine this logic later, i.e., a better policy could be to
adjust the I/O rate using the blkcg with the highest speed from
the list of waiters).

See also:
  https://lkml.org/lkml/2019/3/7/640

Signed-off-by: Andrea Righi <andrea.righi@canonical.com>
---
 include/linux/blk-cgroup.h | 34 +++++++++++++++++++++-------------
 1 file changed, 21 insertions(+), 13 deletions(-)

diff --git a/include/linux/blk-cgroup.h b/include/linux/blk-cgroup.h
index 66d7b6901c77..05e774d55624 100644
--- a/include/linux/blk-cgroup.h
+++ b/include/linux/blk-cgroup.h
@@ -29,6 +29,27 @@
 /* Max limits for throttle policy */
 #define THROTL_IOPS_MAX		UINT_MAX
 
+struct blkcg;
+
+#ifdef CONFIG_CGROUP_WRITEBACK
+
+bool blkcg_wb_waiters_on_bdi(struct blkcg *blkcg, struct backing_dev_info *bdi);
+void blkcg_start_wb_wait_on_bdi(struct backing_dev_info *bdi);
+void blkcg_stop_wb_wait_on_bdi(struct backing_dev_info *bdi);
+
+#else /* CONFIG_CGROUP_WRITEBACK */
+
+static inline bool
+blkcg_wb_waiters_on_bdi(struct blkcg *blkcg, struct backing_dev_info *bdi)
+{
+	return false;
+}
+
+static inline void blkcg_start_wb_wait_on_bdi(struct backing_dev_info *bdi) { }
+static inline void blkcg_stop_wb_wait_on_bdi(struct backing_dev_info *bdi) { }
+#endif /* CONFIG_CGROUP_WRITEBACK */
+
+
 #ifdef CONFIG_BLK_CGROUP
 
 enum blkg_rwstat_type {
@@ -461,10 +482,6 @@ static inline void blkcg_cgwb_put(struct blkcg *blkcg)
 		blkcg_destroy_blkgs(blkcg);
 }
 
-bool blkcg_wb_waiters_on_bdi(struct blkcg *blkcg, struct backing_dev_info *bdi);
-void blkcg_start_wb_wait_on_bdi(struct backing_dev_info *bdi);
-void blkcg_stop_wb_wait_on_bdi(struct backing_dev_info *bdi);
-
 #else
 
 static inline void blkcg_cgwb_get(struct blkcg *blkcg) { }
@@ -474,15 +491,6 @@ static inline void blkcg_cgwb_put(struct blkcg *blkcg)
 	/* wb isn't being accounted, so trigger destruction right away */
 	blkcg_destroy_blkgs(blkcg);
 }
-
-static inline bool
-blkcg_wb_waiters_on_bdi(struct blkcg *blkcg, struct backing_dev_info *bdi)
-{
-	return false;
-}
-static inline void blkcg_start_wb_wait_on_bdi(struct backing_dev_info *bdi) { }
-static inline void blkcg_stop_wb_wait_on_bdi(struct backing_dev_info *bdi) { }
-
 #endif
 
 /**
-- 
2.21.0.777.g83232e3864

